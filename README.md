# Лабораторна робота №2: Ассоціативні правила та кластеризація

## Опис завдання
Реалізувати алгоритми пошуку асоціативних правил (Apriori та FP-Growth) і алгоритми кластеризації (k-Means, k-Medians, ієрархічний single-link, DBSCAN). Провести порівняльний аналіз отриманих результатів та дослідити якість кластеризації залежно від вибору параметрів (наприклад, числа кластерів \(k\)).

## Дані

### Groceries dataset
- **Файл**: `data/groceries.csv`
- **Кількість транзакцій**: 9 835  
- **Джерело**:  
  https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/groceries.csv

### Mall Customers dataset
- **Файл**: `data/Mall_Customers.csv`
- **Кількість зразків**: 200  
- **Джерело**:  
  https://raw.githubusercontent.com/SawyerRen/mall-customer-segmentation-data/master/Mall_Customers.csv

---

## Методи

### Apriori та генерація правил
- **Модуль**: `src/apriori.py`
- **Параметри**:  
  - Мінімальна підтримка (support): 0.02 (2 %)  
  - Мінімальна довіра (confidence): 0.30 (30 %)  
- **Підхід**: ітеративна побудова кандидатних множин \(L_k\), відкидання непоширених, генерація правил та сортування за спаданням довіри й lift.

### FP-Growth
- **Модуль**: `src/fpgrowth.py`
- **Параметри**:  
  - Мінімальна підтримка: 0.02 (2 %)  
- **Підхід**: побудова FP-дерева з header-таблицею, рекурсивний майнінг умовних баз.

### k-Means та k-Medians
- **Модуль**: `src/clustering.py`
- **k-Means**:  
  - Відстань: евклідова  
  - Ініціалізація: випадковий вибір початкових центрів  
  - Поріг збіжності: tol=1e-4  
- **k-Medians** (спадкоємець k-Means):  
  - Відстань: Манхеттен  
  - Центри: медіани координат  

### Ієрархічний алгоритм (single-link)
- **Модуль**: `src/clustering.py`
- **Параметр**: число кластерів \(k\)  
- **Підхід**: агломеративне злиття найближчих за мінімальною відстанню (single-link).

### DBSCAN
- **Модуль**: `src/clustering.py`
- **Параметри**:  
  - eps = 15  
  - min_samples = 5  
- **Підхід**: щільні області за евклідовою відстанню, маркування шумових точок.

---

## Результати

### Аналіз асоціативних правил
- **Часті множини**: 122  
- **Згенеровано правил**: 37  

#### Топ-10 правил за довірою

| №  | Антецедент                           | Консеквент       | Підтримка | Довіра  | Lift |
|----|--------------------------------------|------------------|-----------|---------|------|
| 1  | {other vegetables, yogurt}          | {whole milk}     | 0.022     | 0.513   | 2.01 |
| 2  | {butter}                            | {whole milk}     | 0.028     | 0.497   | 1.95 |
| 3  | {curd}                              | {whole milk}     | 0.026     | 0.490   | 1.92 |
| 4  | {other vegetables, root vegetables} | {whole milk}     | 0.023     | 0.489   | 1.91 |
| 5  | {whole milk, root vegetables}       | {other vegetables}| 0.023    | 0.474   | 2.45 |
| 6  | {domestic eggs}                     | {whole milk}     | 0.030     | 0.473   | 1.85 |
| 7  | {whipped/sour cream}                | {whole milk}     | 0.032     | 0.450   | 1.76 |
| 8  | {root vegetables}                   | {whole milk}     | 0.049     | 0.449   | 1.76 |
| 9  | {root vegetables}                   | {other vegetables}| 0.047    | 0.435   | 2.25 |
| 10 | {frozen vegetables}                 | {whole milk}     | 0.020     | 0.425   | 1.66 |

### Аналіз кластеризації

#### KMeans vs KMedians (k = 2…8)

| k | Inertia (KMeans) | Загальна L1 (KMedians) |
|---|------------------|------------------------|
| 2 | 186234.17        | 6564.00                |
| 3 | 106348.37        | 4897.00                |
| 4 | 73679.79         | 4082.00                |
| 5 | 44448.46         | 3279.00                |
| 6 | 37455.98         | 3055.00                |
| 7 | 36340.53         | 2921.00                |
| 8 | 29999.27         | 2586.00                |

#### Ієрархічний single-link (k = 5)
- **Кількість кластерів**: 5  

#### DBSCAN (eps = 15, min_samples = 5)
- **Кількість кластерів (без шуму)**: 1  
- **Шумових точок**: 6  

---

## Висновки
- Обидва алгоритми Apriori та FP-Growth виявили 122 часті множини при підтримці 2 %, проте FP-Growth має переваги з огляду на ефективність структури FP-дерева при дуже великих об’ємах даних.  
- Для кластеризації кластери ставали дедалі компактнішими зі збільшенням \(k\): інерція KMeans та сумарна L1 KMedians зменшувалися пропорційно, що відображає зростання роздільної здатності.  
- Ієрархічний алгоритм single-link при \(k=5\) чітко виділяє п’ять груп, проте у складних просторах може страждати від «ланцюгового» ефекту.  
- DBSCAN з обраними параметрами об’єднав усі точки у єдиний великий кластер із шістьма шумовими точками, що свідчить про недостатню щільність розподілу для більш гранульованої сегментації.  
- **Рекомендація**: для даної вибірки Mall Customers оптимально обрати \(k \in [4,6]\) у кластерах KMeans/KMedians для балансування компактності та інформативності сегментів.

---

## Посилання
- Приклад звіту: [shalimanov/admp1 README.md](https://github.com/shalimanov/admp1/blob/master/README.md)  
- Groceries dataset (Kaggle mirror): https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/groceries.csv  
- Mall Customers dataset (GitHub mirror): https://raw.githubusercontent.com/SawyerRen/mall-customer-segmentation-data/master/Mall_Customers.csv  
